{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laxmi884/Data_Science_Python_Ass/blob/main/Copy_of_Assignment_Bias_Variance_Tradeoff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq9OIkpjU3hr"
      },
      "source": [
        "# <b> The Boston Housing Dataset is a derived from information collected by the U.S. Census Service concerning housing in the area of Boston MA. The following describes the dataset columns:\n",
        "\n",
        "* CRIM - per capita crime rate by town\n",
        "* ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "* INDUS - proportion of non-retail business acres per town.\n",
        "* CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "* NOX - nitric oxides concentration (parts per 10 million)\n",
        "* RM - average number of rooms per dwelling\n",
        "* AGE - proportion of owner-occupied units built prior to 1940\n",
        "* DIS - weighted distances to five Boston employment centres\n",
        "* RAD - index of accessibility to radial highways\n",
        "* TAX - full-value property-tax rate per \\$10,000\n",
        "* PTRATIO - pupil-teacher ratio by town\n",
        "* B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "* LSTAT - % lower status of the population\n",
        "* MEDV - Median value of owner-occupied homes in $1000's\n",
        "\n",
        "## <b>MEDV is the dependent variable.\n",
        "\n",
        "## Fit polynomial regression on this dataset for degrees 1 to 10. To do such a regression, consider only one variable and then run polynomial fit and plot the train and test errors w.r.t model complexity. You can also repeat this experiment for all the other variables. Also do not use <code>np.polyfit</code>function, but use the <code>LinearRegression()</code> using the scikit-learn library.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0gkUooyR6Ix"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "45Lj-AIEA6Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(path,delimiter = '\\s+',header = None,names=['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','black','lstat','medv',])"
      ],
      "metadata": {
        "id": "8MFolxSVA-N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "07hk3VBYBD3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dependent_variable = 'medv'\n",
        "independent_variables = list(set(df.columns.tolist()) - {dependent_variable})"
      ],
      "metadata": {
        "id": "cA0txUYsBGo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables"
      ],
      "metadata": {
        "id": "3L8N3wpQBKa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_polynomial_regression_model():\n",
        "  \"Creates a polynomial regression model for the given degree\"\n",
        "  fig, axs = plt.subplots(5, 3,figsize=(15, 30))\n",
        "  # j and k is for iterating through axis in subplot\n",
        "  j=0\n",
        "  k=-1\n",
        "  #iterating through each feature variable in data set\n",
        "  for i in independent_variables:\n",
        "    #setting title for plot\n",
        "    title=i\n",
        "\n",
        "    #Create the independent variable data\n",
        "    X = df[i].values\n",
        "    #reshaping it\n",
        "    X = np.array(X).reshape((len(X), 1))\n",
        "\n",
        "    # Create the dependent variable data\n",
        "    y = df[dependent_variable].values\n",
        "\n",
        "    #splitting data into train and test\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "    degree=1\n",
        "\n",
        "    train_error_list=[] #store training error for each degree \n",
        "    test_error_list=[] #store testing error for each degree\n",
        "    degree_list=[1,2,3,4,5,6,7,8,9,10] #storing all the degrees\n",
        "\n",
        "\n",
        "    #iterating through each degree\n",
        "    while degree<=10:\n",
        "      poly_features = PolynomialFeatures(degree=degree)\n",
        "      \n",
        "      # transforms the existing features to higher degree features.\n",
        "      X_train_poly = poly_features.fit_transform(X_train)\n",
        "      \n",
        "      # fit the transformed features to Linear Regression\n",
        "      poly_model = LinearRegression()\n",
        "      poly_model.fit(X_train_poly, Y_train)\n",
        "      \n",
        "      # predicting on training data-set\n",
        "      y_train_predicted = poly_model.predict(X_train_poly)\n",
        "      \n",
        "      # predicting on test data-set\n",
        "      y_test_predict = poly_model.predict(poly_features.fit_transform(X_test))\n",
        "      \n",
        "      # evaluating the model on training dataset\n",
        "      rmse_train = np.sqrt(mean_squared_error(Y_train, y_train_predicted))\n",
        "      train_error_list.append(rmse_train)\n",
        "      \n",
        "      # evaluating the model on test dataset\n",
        "      rmse_test = np.sqrt(mean_squared_error(Y_test, y_test_predict))\n",
        "      test_error_list.append(rmse_test)\n",
        "      degree+=1\n",
        "    # Updating j and k for plotting on subplot  \n",
        "    k+=1\n",
        "    if k>2:\n",
        "      k=0\n",
        "      j+=1\n",
        "    axs[j,k].plot(degree_list,train_error_list,color='green',label='Train_Error')\n",
        "    axs[j,k].plot(degree_list,test_error_list,color='red',linestyle='--',linewidth=1.0,label='Test_Error')\n",
        "    axs[j,k].set_title(title)\n",
        "    axs[j,k].legend()\n",
        "  for ax in axs.flat:\n",
        "    ax.set(xlabel='Model Complexity', ylabel='RMSE')\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mhjVmPBABNnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_polynomial_regression_model()"
      ],
      "metadata": {
        "id": "IB1oGjK6BS4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}